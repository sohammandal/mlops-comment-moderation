{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecaa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "CSV_PATH = \"/Users/sohammandal/Developer/mlops-comment-moderation/assets/comments_test.csv\"   # v1 original\n",
    "MODEL_NAME = \"unitary/toxic-bert\"\n",
    "MAX_LEN = 256            \n",
    "BATCH_SIZE = 64          \n",
    "THRESHOLD = 0.5          \n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ----- Device pick: CUDA -> MPS (Apple GPU) -> CPU -----\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c480ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63978, (63978,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "needed = {\"id\", \"comment_text\", \"moderation_label\"}\n",
    "missing = needed - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV missing columns: {missing}\")\n",
    "\n",
    "texts = df[\"comment_text\"].astype(str).tolist()\n",
    "y_true = df[\"moderation_label\"].astype(int).to_numpy()\n",
    "len(texts), y_true.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0d176c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'toxic',\n",
       " 1: 'severe_toxic',\n",
       " 2: 'obscene',\n",
       " 3: 'threat',\n",
       " 4: 'insult',\n",
       " 5: 'identity_hate'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "num_labels = len(id2label)\n",
    "id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af9446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/sohammandal/Developer/mlops-comment-moderation/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "100%|██████████| 1000/1000 [16:55<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Batched inference\n",
    "def batched(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield i, iterable[i:i+n]\n",
    "\n",
    "all_probs = np.zeros((len(texts), num_labels), dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start_idx, batch_texts in tqdm(list(batched(texts, BATCH_SIZE))):\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        end_idx = start_idx + len(batch_texts)\n",
    "        all_probs[start_idx:end_idx, :] = probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa397d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9891    0.9199    0.9532     57735\n",
      "           1     0.5502    0.9063    0.6847      6243\n",
      "\n",
      "    accuracy                         0.9186     63978\n",
      "   macro avg     0.7697    0.9131    0.8190     63978\n",
      "weighted avg     0.9463    0.9186    0.9270     63978\n",
      "\n",
      "\n",
      "F1 weighted: 0.9270 | F1 macro: 0.8190\n"
     ]
    }
   ],
   "source": [
    "# positive if ANY label prob > THRESHOLD\n",
    "y_hat = (all_probs.max(axis=1) > THRESHOLD).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(classification_report(y_true, y_hat, digits=4))\n",
    "f1_macro = f1_score(y_true, y_hat, average=\"macro\")\n",
    "f1_weighted = f1_score(y_true, y_hat, average=\"weighted\")\n",
    "print(f\"\\nF1 weighted: {f1_weighted:.4f} | F1 macro: {f1_macro:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-comment-moderation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
